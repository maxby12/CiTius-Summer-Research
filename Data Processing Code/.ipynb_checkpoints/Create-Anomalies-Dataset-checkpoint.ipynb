{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import json\n",
    "\n",
    "from skimage import io, img_as_ubyte, img_as_float\n",
    "from skimage.draw import random_shapes\n",
    "from skimage.filters import gaussian\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import rotate\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.04 ms\n"
     ]
    }
   ],
   "source": [
    "def normalize_img_values(img):\n",
    "    img = img - img.min()\n",
    "    img = img / img.max()\n",
    "    img = img_as_ubyte(img)\n",
    "    return img\n",
    "\n",
    "def check_normalized(img):\n",
    "    try:\n",
    "        assert img.shape == (256, 256, 3), 'Error in shape of a read image '+str(img.shape)\n",
    "        assert img.dtype == np.uint8, 'Error in dtype of a read image '+str(img.dtype)\n",
    "        assert img.max() == 255, 'Error in max value of a read image '+str(img.max())\n",
    "        assert img.min() == 0, 'Error in min value of a read image '+str(img.min())\n",
    "        \n",
    "    except AssertionError:\n",
    "        return normalize_img_values(img_as_float(img))\n",
    "    \n",
    "    return img\n",
    "\n",
    "def check_normalized_patch(patch, patch_size=64):\n",
    "    try:\n",
    "        assert patch.shape == (patch_size, patch_size, 3), 'Error in shape of a read patch '+str(patch.shape)\n",
    "        assert patch.dtype == np.uint8, 'Error in dtype of a read patch '+str(patch.dtype)\n",
    "        assert patch.max() == 255, 'Error in max value of a read patch '+str(patch.max())\n",
    "        assert patch.min() == 0, 'Error in min value of a read patch '+str(patch.min())\n",
    "        \n",
    "    except AssertionError:\n",
    "        return normalize_img_values(img_as_float(patch))\n",
    "    \n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.24 s\n"
     ]
    }
   ],
   "source": [
    "# CREATE A PATCHED DATASET FROM THE BARK DATASET\n",
    "\n",
    "offset_area = 32\n",
    "anomaly_diameter = 42\n",
    "num_images = 500\n",
    "image_size = 256\n",
    "anomaly_size = image_size - 2*offset_area\n",
    "dataset_path = '../Datasets/Bark-dataset-Test/'\n",
    "\n",
    "files = os.listdir(dataset_path)\n",
    "random.shuffle(files)\n",
    "\n",
    "img_count = 0\n",
    "selected_images = []\n",
    "for filename in files:\n",
    "    if '.jpg' not in filename: continue\n",
    "    \n",
    "    img = io.imread(dataset_path+filename)\n",
    "    img = check_normalized(img)\n",
    "    #print(img.shape, img.dtype, img.max(), img.min())\n",
    "    selected_images.append(img)\n",
    "    img_count += 1\n",
    "    if img_count == num_images: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.36 ms\n"
     ]
    }
   ],
   "source": [
    "def get_external_crops(external_anomaly_num, rotate=False):\n",
    "    for i in range(external_anomaly_num):\n",
    "        candidates = list(range(i)) + list(range(i+1, num_images))\n",
    "        anomaly_origin = selected_images[ random.choice(candidates) ]\n",
    "        row, col = random.randint(0, image_size-anomaly_diameter), random.randint(0, image_size-anomaly_diameter)\n",
    "        crop = anomaly_origin[row:row+anomaly_diameter, col:col+anomaly_diameter, :]\n",
    "        crop = np.copy(crop)\n",
    "        yield crop if not rotate else rotate(crop, random.randint(0, 90), resize=False, preserve_range=True, mode='symmetric')\n",
    "        \n",
    "\n",
    "def insert_anomaly(anomaly_area, anomaly):\n",
    "    anom_rows, anom_cols, _ = anomaly.shape\n",
    "    row, col = random.randint(0, anomaly_size-anom_rows), random.randint(0, anomaly_size-anom_cols)\n",
    "    anomaly_area[row:row+anom_rows, col:col+anom_cols, :] = anomaly\n",
    "    return row+int(anom_rows/2)+offset_area, col+int(anom_cols/2)+offset_area\n",
    "\n",
    "\n",
    "def random_color_anomaly(anomaly_area, colour_range_noise=(0,0), sigma=4, alpha=0.2):\n",
    "    mean_colours = int(round(np.mean(anomaly_area[:,:,0]))), int(round(np.mean(anomaly_area[:,:,1]))), int(round(np.mean(anomaly_area[:,:,2])))\n",
    "    mean_ranges_colours = ( (max(mean_colours[0]-colour_range_noise[0], 0), min(mean_colours[0]+colour_range_noise[1], 255) ),\n",
    "                           (max(mean_colours[1]-colour_range_noise[0], 0), min(mean_colours[1]+colour_range_noise[1], 255) ),\n",
    "                           (max(mean_colours[2]-colour_range_noise[0], 0), min(mean_colours[2]+colour_range_noise[1], 255) ) )\n",
    "    #print(mean_ranges_colours)\n",
    "    \n",
    "    anomaly_generation, labels = random_shapes(anomaly_area.shape, max_shapes=1, min_size=anomaly_diameter,\n",
    "                                 max_size=anomaly_diameter, intensity_range=mean_ranges_colours)\n",
    "    \n",
    "    #print(anomaly_area.shape, anomaly_area.dtype, anomaly_area.max(), anomaly_area.min())\n",
    "    #print(labels)\n",
    "    \n",
    "    anomaly_generation = gaussian(anomaly_generation, sigma=sigma, multichannel=True)\n",
    "    anomaly_generation = anomaly_generation - anomaly_generation.min()\n",
    "    anomaly_generation = anomaly_generation / anomaly_generation.max()\n",
    "    anomaly_generation = anomaly_generation * 255\n",
    "    anomaly_generation = anomaly_generation.astype(np.uint8)\n",
    "    \n",
    "    #plt.imshow(anomaly_generation)\n",
    "    #plt.show()\n",
    "    \n",
    "    color_step = 15\n",
    "    alpha_increment = 0.075\n",
    "    for i in range(1,15):\n",
    "        indices = np.where(anomaly_generation < 175-i*color_step)\n",
    "        anomaly_area[indices] = alpha*anomaly_generation[indices] + (1-alpha)*anomaly_area[indices]\n",
    "        alpha = min(alpha+alpha_increment, 0.99)\n",
    "        \n",
    "    rows, cols = labels[0][1]\n",
    "    return int( (rows[1]+rows[0])/2 )+offset_area, int( (cols[1]+cols[0])/2 )+offset_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "External anomalies: 375\n",
      "Colour anomalies: 125\n",
      "time: 3.43 s\n"
     ]
    }
   ],
   "source": [
    "assert len(selected_images) == num_images,'Selected images not equal to number of the desired ones'\n",
    "\n",
    "external_anomaly_ratio = 0.75\n",
    "external_anomaly_num = int(external_anomaly_ratio*num_images)\n",
    "rotate_external_anomalies = False\n",
    "colour_range_noise = (15, 0)\n",
    "output_path = '../Datasets/Bark-1C3E-Quantitative/'\n",
    "\n",
    "if not os.path.exists(output_path): os.mkdir(output_path)\n",
    "\n",
    "centers = {}\n",
    "external_crops = list(get_external_crops(external_anomaly_num, rotate=rotate_external_anomalies))\n",
    "num_colour, num_external, count = 0, 0, 0\n",
    "for i in range(num_images):\n",
    "    img = selected_images[i]\n",
    "    anomaly_area = img[offset_area:-offset_area,offset_area:-offset_area,:]\n",
    "    \n",
    "    if num_external < external_anomaly_num:\n",
    "        # INSERT EXTERNAL CROP TO THE IMAGE\n",
    "        anomaly = external_crops[i]\n",
    "        row, col = insert_anomaly(anomaly_area, anomaly)\n",
    "        \n",
    "        io.imsave(output_path+'an_'+str(count)+'.jpg', img)\n",
    "        num_external += 1\n",
    "    else:\n",
    "        # MODIFY A PATCH FROM THE IMAGE\n",
    "        row, col = random_color_anomaly(anomaly_area, colour_range_noise, sigma=3)\n",
    "\n",
    "        io.imsave(output_path+'an_'+str(count)+'.jpg', img)\n",
    "        num_colour += 1\n",
    "    \n",
    "    centers[count] = (row, col)\n",
    "    count += 1\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "    #break\n",
    "    \n",
    "with open('../Datasets/'+output_path.split('/')[-2]+'.json', 'w') as outfile:  \n",
    "    json.dump(centers, outfile, sort_keys=True, indent=4)\n",
    "    \n",
    "print('External anomalies:', num_external)\n",
    "print('Colour anomalies:', num_colour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
