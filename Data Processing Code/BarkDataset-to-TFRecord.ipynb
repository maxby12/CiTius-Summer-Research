{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "from skimage import io, img_as_float, img_as_ubyte\n",
    "from skimage.transform import rescale, resize\n",
    "from skimage.util import view_as_blocks\n",
    "\n",
    "# Features when reading Examples\n",
    "features = {\n",
    "    'rows': tf.FixedLenFeature([], tf.int64),\n",
    "    'cols': tf.FixedLenFeature([], tf.int64),\n",
    "    'channels': tf.FixedLenFeature([], tf.int64),\n",
    "    'image': tf.FixedLenFeature([], tf.string),\n",
    "    'label': tf.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_with_filename(filename):\n",
    "    name = filename.split('/')[-1]\n",
    "    label = name.split('.')[0]\n",
    "    class_id, img_count = label.split('_')\n",
    "    return int(img_count)\n",
    "\n",
    "def get_patch_count(filename):\n",
    "    name = filename.split('/')[-1]\n",
    "    label = name.split('.')[0]\n",
    "    class_id, img_count = label.split('_')\n",
    "    return int(img_count)\n",
    "\n",
    "def get_count(filename):\n",
    "    name = filename.split('/')[-1]\n",
    "    count = name.split('.')[0]\n",
    "    return int(count)\n",
    "\n",
    "def get_anomaly_count(filename):\n",
    "    name = filename.split('/')[-1]\n",
    "    label = name.split('.')[0]\n",
    "    img_count = label.split('_')[-1]\n",
    "    return int(img_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASS TO GENERATE A TFRECORD FROM ALL THE IMAGES IN A FOLDER\n",
    "class GenerateTFRecord:\n",
    "\n",
    "    def convert_image_folder(self, img_folder, tfrecord_file_name):\n",
    "        # Get all file names of images present in folder\n",
    "        img_paths = os.listdir(img_folder)\n",
    "        img_paths = [os.path.abspath(os.path.join(img_folder, i)) for i in img_paths]\n",
    "        \n",
    "        img_paths.sort(key=lambda x: get_anomaly_count(x))\n",
    "\n",
    "        with tf.python_io.TFRecordWriter(tfrecord_file_name) as writer:\n",
    "            for img_path in img_paths:\n",
    "                example = self._convert_image(img_path)\n",
    "                writer.write(example.SerializeToString())\n",
    "                \n",
    "    def _convert_image(self, img_path):\n",
    "        label = get_anomaly_count(img_path)\n",
    "        img_shape = mpimg.imread(img_path).shape\n",
    "        \n",
    "#         filename = os.path.basename(img_path)\n",
    "\n",
    "        # Read image data in terms of bytes\n",
    "        with tf.gfile.GFile(img_path, 'rb') as fid:\n",
    "            image_data = fid.read()\n",
    "            \n",
    "        # If image has more than 1 channels wirte the number of channels\n",
    "        # otherwise write a 1 in the channels feature\n",
    "        channels = img_shape[2] if len(img_shape)==3 else 1\n",
    "        \n",
    "        example = tf.train.Example(features = tf.train.Features(feature = {\n",
    "#             'filename': tf.train.Feature(bytes_list = tf.train.BytesList(value = [filename.encode('utf-8')])),\n",
    "            'rows': tf.train.Feature(int64_list = tf.train.Int64List(value = [img_shape[0]])),\n",
    "            'cols': tf.train.Feature(int64_list = tf.train.Int64List(value = [img_shape[1]])),\n",
    "            'channels': tf.train.Feature(int64_list = tf.train.Int64List(value = [channels])),\n",
    "            'image': tf.train.Feature(bytes_list = tf.train.BytesList(value = [image_data])),\n",
    "            'label': tf.train.Feature(int64_list = tf.train.Int64List(value = [label])),\n",
    "        }))\n",
    "        return example\n",
    "    \n",
    "    \n",
    "# CLASS TO EXTRACT IMAGES FROM A TFRECORD AND RETURN A DATASET\n",
    "class TFRecordExtractor:\n",
    "    def __init__(self, tfrecord_file):\n",
    "        self.tfrecord_file = os.path.abspath(tfrecord_file)\n",
    "\n",
    "    def _extract_fn(self, tfrecord):\n",
    "        # Extract the data record\n",
    "        sample = tf.parse_single_example(tfrecord, features)\n",
    "\n",
    "        # cast image [0, 255] to [0.0, 1.0]\n",
    "        image = tf.image.decode_image(sample['image'], dtype=tf.uint8)\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image = image / 255\n",
    "        \n",
    "        #print(image.dtype)\n",
    "        img_shape = tf.stack([sample['rows'], sample['cols'], sample['channels']])\n",
    "        label = sample['label']\n",
    "        label = tf.cast(label, tf.int64)\n",
    "        #filename = sample['filename']\n",
    "        \n",
    "        return image\n",
    "\n",
    "    def extract_image(self):\n",
    "\n",
    "        # Pipeline of dataset\n",
    "        dataset = tf.data.TFRecordDataset([self.tfrecord_file])\n",
    "        dataset = dataset.map(self._extract_fn)\n",
    "        \n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A TFRECORD FROM AN IMAGES FOLDER\n",
    "t = GenerateTFRecord()\n",
    "\n",
    "datasets_path = '../Datasets/'\n",
    "tfrecords_path = '../TFRecords/'\n",
    "\n",
    "if not os.path.exists(tfrecords_path): os.mkdir(tfrecords_path)\n",
    "\n",
    "#train_name = 'Bark-dataset-Train'\n",
    "test_name = 'Bark-Clear-Quantitative'\n",
    "\n",
    "#t.convert_image_folder(datasets_path+train_name, tfrecords_path+train_name+'.tfrecord')\n",
    "t.convert_image_folder(datasets_path+test_name, tfrecords_path+test_name+'.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 256\n",
    "input_size = 128\n",
    "crop_size = 32\n",
    "\n",
    "crop_ratio = 0.5\n",
    "def random_crop(image):\n",
    "    crop_size = tf.random_uniform(shape=[], minval=150, maxval=200, dtype=tf.int32)\n",
    "    image = tf.image.random_crop(image, size=(crop_size,crop_size,3))\n",
    "    image = tf.image.resize(image, size=(image_size,image_size))\n",
    "    return image\n",
    "\n",
    "def map_test(image, label):\n",
    "    do_crop = tf.random_uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
    "    image = tf.cond(tf.less(do_crop, crop_ratio), lambda: random_crop(image), lambda: image)\n",
    "\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.25)\n",
    "    image = tf.image.random_saturation(image, lower=0.75, upper=1.25)\n",
    "    image = tf.image.random_contrast(image, lower=0.75, upper=1.25)\n",
    "    image = tf.image.random_hue(image, max_delta=0.15)\n",
    "    return image, label\n",
    "\n",
    "def get_patches(image, label):\n",
    "    ksizes=[1,input_size,input_size,1]\n",
    "    strides=[1,crop_size,crop_size,1]\n",
    "    rates=[1,1,1,1]\n",
    "    patches = tf.image.extract_image_patches(tf.reshape(image, (1, 256, 256, 3)),ksizes,strides,rates,padding='VALID')\n",
    "    num_patches = int( (image_size/input_size)**2 )\n",
    "    return tf.reshape(patches, (-1, input_size, input_size, 3))\n",
    "\n",
    "def reduced_train_input_fn(dataset, samples=100):\n",
    "    dataset = dataset.map(get_patches, num_parallel_calls=tf.data.experimental.AUTOTUNE)#.apply(tf.data.experimental.unbatch())\n",
    "    dataset = dataset.take(samples)\n",
    "    #dataset = dataset.batch(8)\n",
    "    dataset = dataset.prefetch(1)  # make sure you always have one batch ready to serve\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TEST THE READING AND PARSING OF THE TRAINING TFRECORD INTO A DATASET\n",
    "t = TFRecordExtractor(tfrecords_path+test_name+'.tfrecord')\n",
    "dataset = t.extract_image().batch(8)\n",
    "#dataset = reduced_train_input_fn(dataset)\n",
    "#dataset = dataset.map(map_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "#dataset = dataset.map(get_patches, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "patch_count = 0\n",
    "i, j = 0, 0\n",
    "for batch in dataset:\n",
    "    print(batch.shape)\n",
    "    \n",
    "    for image in batch:\n",
    "        print(image.shape)\n",
    "        \n",
    "        if i+j == 0:\n",
    "            f, axarr = plt.subplots(ncols=2, nrows=2, figsize=(15, 7))\n",
    "\n",
    "        axarr[i,j].imshow(image)\n",
    "        axarr[i,j].set_title(str(patch_count))\n",
    "\n",
    "        if i==1 and j==1:\n",
    "            plt.show()\n",
    "            i, j = 0, 0\n",
    "        else:\n",
    "            if j==1:\n",
    "                i += 1\n",
    "                j = 0\n",
    "            else:\n",
    "                j += 1\n",
    "        patch_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TEST THE READING AND PARSING OF THE TRAINING TFRECORD INTO A DATASET\n",
    "t = TFRecordExtractor(tfrecords_path+test_name+'.tfrecord')\n",
    "dataset = t.extract_image()\n",
    "#dataset = dataset.map(map_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "patch_count = 0\n",
    "i, j = 0, 0\n",
    "for sample in dataset.take(10):\n",
    "    if i+j == 0:\n",
    "        f, axarr = plt.subplots(ncols=2, nrows=2, figsize=(15, 7))\n",
    "    \n",
    "    image, label = sample[0].numpy(), sample[1].numpy()\n",
    "    \n",
    "    axarr[i,j].imshow(image)\n",
    "    axarr[i,j].set_title(str(label))\n",
    "    \n",
    "    if i==1 and j==1:\n",
    "        plt.show()\n",
    "        i, j = 0, 0\n",
    "    else:\n",
    "        if j==1:\n",
    "            i += 1\n",
    "            j = 0\n",
    "        else:\n",
    "            j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "el = iterator.get_next()\n",
    "# print(el)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer)\n",
    "    for i in range(10):\n",
    "        sample = sess.run(el)\n",
    "        img = sample[0]\n",
    "        label = sample[1]\n",
    "\n",
    "        print(img.shape, label)\n",
    "        img = np.reshape(img, newshape= (img.shape[0], img.shape[1], img.shape[2]) )\n",
    "        print(img.max(), img.min())\n",
    "\n",
    "        f, axarr = plt.subplots(ncols=1, nrows=1, figsize=(1, 1))\n",
    "        axarr.imshow(img)\n",
    "        axarr.set_title('Example image')\n",
    "        plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
